# MongoDB: Lookup, Transactions, Aggregation framework, Indexes, Monitoring, Replica set and sharding

**Документо-ориентированная БД.**

Структура

    MongoDB
    └── Database
      └── Collection
        └── Document (BSON).

CAP: CP (согласованность и устойчивость к сетевым разделениям).

---

## _id и ObjectId:
1. _id
   - Обязательное поле для каждого документа.
   - Используется как уникальный идентификатор и PK.
   - Если ты не задаёшь его вручную — Mongo автоматически создаёт его как ObjectId.
   - Каждый документ всегда имеет _id. Без него он просто не может существовать в коллекции.
   - Сортируется по дате создания.
2. ObjectId
   - Специальный BSON-тип данных. Выглядит как строка из 24 символов
     ObjectId("665d067f3c2e6a3f91fc4e20")
   - Уникальный идентификатор, встроенный в MongoDB. Гарантирует уникальность на всех машинах и во всех коллекциях.
   - Позволяет автоматически сортировать по времени.

---

## lookup
Используется для выполнения операции, аналогичной LEFT OUTER JOIN в SQL.

    {
        $lookup: {
            from: <collection to join>,
            localField: <field from the input documents>,
            foreignField: <field from the documents of the "from" collection>,
            as: <output array field>
        }
    }

- **from** — Указывает коллекцию, с которой нужно выполнить объединение.
- **localField** — Указывает поле из документов входной коллекции, по которому будет выполняться объединение.
- **foreignField** — Указывает поле из документов коллекции from, по которому будет выполняться объединение.
- **as** — Указывает имя нового массива, который будет добавлен в выходные документы и содержать совпадающие документы из коллекции from.
  
_Пример:_ у вас есть две коллекции: orders и customers. Вы хотите объединить заказы с информацией о клиентах:

    db.orders.aggregate([
      {
          $lookup: {
              from: "customers",
              localField: "customer_id",
              foreignField: "_id",
              as: "customer_info"
          }
      }
    ])

#### Пример запросов
1. _Добавить нового пользователя_:

   
    db.users.insertOne({
       name: "Max",
       age: 24,
       skills: ["Java", "Spring Boot"]
    })

2. _Найти пользователей с Java и возрастом > 20_:

   
    db.users.find({
       age: { $gt: 20 },
       skills: "Java"
    })
3. _Увеличить возраст всем пользователям на 1_:
   `db.users.updateMany({}, { $inc: { age: 1 } })`
4. _Удалить всех младше 18_:
   `db.users.deleteMany({ age: { $lt: 18 } })`
5. _Найдёт всех, кто моложе 18 или живет в Тбилиси_:

   
    db.users.find({
       $or: [
           { age: { $lt: 18 } },
           { "address.city": "Tbilisi" }
       ]
    })
6. _Найдёт все товары, относящиеся к одной из указанных категорий_:

   
    db.products.find({
        category: { $in: ["books", "electronics"] }
    })
7. _Вложенные поля (dot notation)_:

   
    db.users.find({
        "address.zip": "0101"
    })

---

## Best practices
1. Проектируй от use-case'а, а не от модели предметной области. Денормализуем и проектируем под частые операции.
2. Embed (вложенность) vs Reference (ссылки) — Если отношение «один-к-нескольким» и количество поддокументов разумное (до 1000) → вкладывай.
    2.1 Embed
   - Хорошо, если данные используются вместе.
   - Уменьшает число запросов (no joins).
   - Повышает скорость чтения.
   - Плохо масштабируется при частых изменениях вложенного.
  
   2.2 Reference
   - Хорошо для связей многие-ко-многим.
   - Лучше при больших вложенных массивах.
   - Удобно при повторном использовании сущностей.
   - Требует дополнительных запросов/агрегаций.

3. Старайся избежать слишком больших документов
   - Документ не должен превышать 16 МБ.
   - Чем больше документ, тем выше нагрузка на сеть, диск и RAM.
   - Частые обновления внутри больших документов — write amplification и внутренние пересоздания.
4. Частичный апдейт vs перезапись

    4.1 Частичный апдейт
      `db.users.updateOne(
        { _id: ObjectId("...") },
        { $set: { age: 29, city: "Batumi" } }
      )`
    
    4.2 Полная перезапись
`       db.users.updateOne(
          { _id: ObjectId("...") },
          {
             name: "Ivan",
             age: 29
          }
       )`

    4.3 Updates:
   - Всегда используй $set (и другие операторы), если тебе не нужен полный wipe.
   - Добавляй $unset для удаления отдельных полей.
   - Используй $push, $pull, $addToSet для работы с массивами.
   - Если нужно добавить поле только если его нет — используй $setOnInsert.

---

## Transactions

### ACID
- **Atomicity** — На уровне документа; много-документные транзакции с 4.0+, в Sharded Cluster с 4.2.
- **Consistency** — Опционально: можно внедрять валидацию схемами и логикой.
- **Isolation** — Да, через snapshot isolation внутри транзакций.
- **Durability** — Journaling + writeConcern: { j: true }.

#### Используй транзакции, если:
- обновляешь несколько коллекций.
- это финансовые операции.
- тебе нужна строгая согласованность.

#### Не злоупотребляй:
- это дорогая операция, удерживает логи и тормозит производительность.
- большинство кейсов в Mongo можно решить без них (вложенностью и денормализацией).

#### Concerns
1. **Write concern** — параметр определяет сколько узлов должны подтвердить выполненую операцию перед тем как подтвердить успех клиенту.
   - w: 1 (default) — Запись подтверждена основным узлом.
   - w: "majority" — Подтверждена большинством реплик.
   - j: true — Подтверждена после записи в журнал.
   - wtimeout — Ограничение по времени ожидания.
     `db.orders.insertOne(order, { writeConcern: { w: "majority", j: true, wtimeout: 5000 } })`
2. **Read Concern** — настройка, определяющая какие данные может видеть клиент (насколько "свежие" или "подтверждённые").
   - local — Все данные, включая нераспространённые.
   - majority — Только подтверждённые большинством.
   - snapshot — Используется внутри транзакций — гарантирует стабильный view.

#### Mongo использует оптимистичную изоляцию:
- Пока ты читаешь — другие могут писать.
- Конфликты проверяются при commit() — если изменения в объекте уже были, транзакция может быть отклонена (write conflict).

**Поэтому желательно:**
- Избегать долгих транзакций.
- Обновлять маленькие порции.
- Учитывать, что при конфликте — лучше повторить попытку (retry logic).

---

## Aggregation framework

**Aggregation Pipeline** — последовательность этапов обработки документов (pipeline stages), где каждый шаг преобразует данные и передаёт их дальше.

    db.collection.aggregate([
        { $stage1: { ... } },
        { $stage2: { ... } },
        ...
    ])

### Основные этапы
1. **match** — Фильтрация документов (как find()): 
   `{ $match: { status: "PAID" } }`
2. **project** — Выбор полей, создание новых, переименование, вычисления: 
   `{ $project: { name: 1, age: 1, isAdult: { $gte: ["$age", 18] } } }`
3. **group** — Группировка по полю + агрегатные функции: 
   `{ $group: { _id: "$status", total: { $sum: "$amount" } } }`
4. **sort** — Сортировка: 
   `{ $sort: { createdAt: -1 } }`
5. **limit**, $skip  — Аналоги LIMIT, OFFSET: 
   `{ $limit: 10 }`
6. **unwind** — Разворачивает массив в несколько документов: 
   `{ $unwind: "$tags" }` :
   Из:
   `{ name: "Book", tags: ["tech", "mongo"] }` → `{ name: "Book", tags: "tech" }` , `{ name: "Book", tags: "mongo" }`
7. **lookup** — Аналог JOIN :
   Вставит массив user с совпадениями.


    {
        $lookup: {
            from: "users",
            localField: "userId",
            foreignField: "_id",
            as: "user"
        }
    }
   
8. **addFields** — Добавляет или изменяет поля: 
   `{ $addFields: { discount: { $cond: [ { $gte: ["$price", 100] }, 10, 0 ] } } }`
9. **merge** — Сохраняет результат агрегации в другую коллекцию: 
   `{ $merge: "reports" }`

**Агрегатные функции:** `sum, avg, min, max, count, first, last.`

### Примеры агрегаций
1. _Подсчёт количества заказов по статусу:_
   

    db.orders.aggregate([
      { $match: { createdAt: { $gte: ISODate("2024-01-01") } } },
      { $group: { _id: "$status", total: { $sum: 1 } } },
      { $sort: { total: -1 } }
    ])
2. _Средний возраст пользователей по городу:_
   

    db.users.aggregate([
        { $group: { _id: "$address.city", avgAge: { $avg: "$age" } } }
    ])
3. _Количество товаров в каждой категории:_
   

    db.products.aggregate([
        { $group: { _id: "$category", count: { $sum: 1 } } }
    ])
4. _Соединение заказов и пользователей через $lookup:_
   

    db.orders.aggregate([
        {
            $lookup: {
                from: "users",
                localField: "userId",
                foreignField: "_id",
                as: "user"
            }
        },
        { $unwind: "$user" },
        { $project: { total: 1, "user.name": 1 } }
    ])

#### Производительность агрегаций
- Ставь $match и $project как можно раньше.
- Используй индексы до агрегации.
- Избегай $lookup, если можно обойтись embed'ами.
- Используй explain() для профилирования.
- Делай агрегацию по _id или индексируемым полям.

---

## Indexes

Специальная структура данных, которая ускоряет поиск документов по определённым полям, подобно индексам в книгах.
- Без индекса Mongo перебирает все документы.
- С индексом — переходит сразу к нужным документам (log(N)).

Типы индексов
1. Single Field Index
   - Быстро ищет, сортирует и фильтрует по email.
   - Применим к равенствам, $gt, $lt, $in, сортировкам.
     
     `db.users.createIndex({ email: 1 }) // 1 = ASC, -1 = DESC.`.
2. Compound Index (составной)
   - Покрывает сначала age, потом city.
   - Может использоваться, если ты фильтруешь по age, или по обоим age + city.
   - Но не используется, если только city → порядок важен!
     
     `db.users.createIndex({ age: 1, city: 1 })`.
3. Multikey Index (по массиву)
   - Если tags — массив, Mongo создаёт по каждому элементу.
   - Позволяет эффективно искать документы по отдельным значениям массива.
     
     `db.posts.createIndex({ tags: 1 })`.
4. Text Index
   - Позволяет использовать $text для полнотекстового поиска.
   - Поддерживает language, stop words, stemming.
     
     `db.articles.createIndex({ content: "text" })`.
     
     Здесь content — это поле, по которому будет выполняться текстовый поиск.
     Применение текстового индекса:
     
     `db.collection.find({ $text: { $search: "example text" } });`.
5. Hashed Index
   - Используется для равномерного распределения данных по шардированным кластерам.
   - Нельзя использовать для диапазонных запросов ($gt, $lt).
     
     `db.users.createIndex({ userId: "hashed" })`.
6. TTL Index
   - MongoDB автоматически удалит документы спустя заданное время.
   - Поле должно быть типа Date.
     
     `db.sessions.createIndex({ createdAt: 1 }, { expireAfterSeconds: 3600 })`.
7. Partial Index
   - Индексируется только часть коллекции.
   - Экономит место, ускоряет частые запросы по конкретным условиям.
     
     `db.orders.createIndex({ status: 1 }, { partialFilterExpression: { status: { $eq: "PAID" } } })`.

### Mongo выбирает индекс используя Query Planner:
- Выбирает наиболее селективный индекс (который отфильтрует больше всего).
- Может использовать один индекс на запрос.
- Использует compound индекс, если ты фильтруешь по его начальным полям.

### Проверка индекса
`db.users.find({ age: { $gt: 25 } }).explain("executionStats")`
Смотри на:
- stage: "IXSCAN" — использован индекс, "COLLSCAN" — полный перебор.
- nReturned vs totalDocsExamined.
- indexName.
- keysExamined — сколько индексов просмотрено.
- COLLSCAN — нужен индекс.

### Покрывающий индекс (Covered Query)
Если все поля запроса и проекции содержатся в индексе, Mongo не обращается к самому документу:

`db.users.find({ email: "test@test.com" }, { email: 1, _id: 0 })`

если есть индекс по email, Mongo вернёт результат без доступа к документу
Быстро, экономит ресурсы

---

## Monitoring

### Slow Query Log
MongoDB логирует все медленные запросы, если включить соответствующую настройку в _mongod.conf_:

`operationProfiling:
    slowOpThresholdMs: 100
    mode: slowOp`

Или временно:
`db.setProfilingLevel(1, { slowms: 100 })`

### Показатели метрик
db.stats() — Общая статистика БД.
db.serverStatus() — ВСЕ системные метрики.
db.collection.stats()  — Размеры, индексы, документы.

Особое внимание на:
- objects, avgObjSize, storageSize, indexSize.
- opcounters.query, opcounters.insert — нагрузка.
- connections.current — подключено клиентов.
- wiredTiger.cache — использование оперативной памяти.

### Инструменты для мониторинга
- mongotop показывает, сколько времени коллекции проводят в чтении/записи.
- mongostat — текущая нагрузка: вставки, чтения, соединения, активные опер.

---

## Replica set

### Структура
- Primary — главный узел, принимает записи
- Secondary — один или несколько, реплицируют данные от Primary
- Arbiter (опционально) — участвует в выборах, но не хранит данные
  Минимум 3 узла: 1 Primary + 2 Secondary, либо 1 Primary + 1 Secondary + 1 Arbiter.

### Как работает репликация
- Все записи идут только на Primary.
- Secondary-узлы асинхронно реплицируют операции (oplog) от Primary.
- Если Primary падает → проходит автоматический перевыбор (failover) → один из Secondary становится новым Primary.
- Репликация построена на Oplog — журнале всех операций записи (insert, update, delete).

### Failover и автоматическое восстановление
MongoDB использует автоматические выборы с помощью протокола Raft-подобного консенсуса:
- Когда Primary недоступен > 10 секунд → начинается голосование.
- Каждый узел голосует за кандидата (нужно большинство голосов, например, 2 из 3).
- Новый Primary начинает принимать записи.
- Старый Primary при возврате становится Secondary.
  Это позволяет MongoDB работать даже при сбоях одного сервера — без вмешательства администратора

### Arbiter
Это узел, который не хранит данные, но голосует в выборах.
Когда нужен:
- У тебя только 2 узла с данными (Primary и Secondary), но тебе нужно 3-й голос → добавь Arbiter.
- Он очень лёгкий, может быть развёрнут даже на слабом VPS.
  Не рекомендуется на проде, если безопасность важна (у арбитра нет данных → возможен split-brain при взломе).

### Oplog (операционный журнал)
- Каждый узел хранит oplog.rs — специальную capped collection, содержащую последовательность операций.
- Secondary узлы реплеят операции в том же порядке.
  
Это позволяет:
- восстановить синхронность.
- читать состояние на определённый момент времени.
- делать oplog-based backup.

### Важные параметры и команды
- rs.initiate() — инициализация Replica Set.
- rs.status() — состояние узлов.
- rs.add() / rs.remove() — добавление/удаление узлов.
- rs.stepDown() — форсировать смену Primary.
- rs.conf() / rs.reconfig() — конфигурация Replica Set.

---

## Sharding

- Коллекция шардиется по ключу шардинга
- Mongo разбивает данные на чанки (chunks) по диапазону ключа
- Чанки распределяются по шардам
- mongos направляет запрос в нужный шард
  Пример: шард по userId. Тогда пользовательские данные будут распределены по диапазонам userId.

Выбор ключа шардинга — самый важный шаг.
1. Равномерный (userId, hashed) — Высокая вставка, распределение — Плохо подходит для диапазонов.
2. Диапазонный (timestamp, date) — Поиск по датам, отчёты — Риск горячих шардов (hotspot).
3. Составной — Комбинация фильтрации + уникальности — Нужно знать паттерны запроса.

Mongo отслеживает, сколько чанков на каждом шарде, и автоматически балансирует.
mongos анализирует 'ключ шардинга' и 'метаданные с config servers', и направляет запрос только в нужный шард (или в несколько, если ключ не указан — это scatter-gather).

Технические детали
- Чанк = диапазон по ключу (по умолчанию 64MB).
- Шард можно представить как логически независимую базу.
- Балансер делит чанки, если они слишком большие.
- Раз в 10 сек mongos запрашивает метаинфу у config servers.